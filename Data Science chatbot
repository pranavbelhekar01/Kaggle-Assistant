{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":64148,"databundleVersionId":7669720,"sourceType":"competition"},{"sourceId":7923451,"sourceType":"datasetVersion","datasetId":4633221},{"sourceId":28785,"sourceType":"modelInstanceVersion","modelInstanceId":8318}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hussh.ai\n\n## Dataset Used\n* [1000-Data-Science-Concepts](https://www.kaggle.com/datasets/hserdaraltan/1000-data-science-concepts) : This dataset covers more than 1000 common data science concepts. It covers several topics related to Statistics, Machine Learning, and Artificial Intelligence. It has two columns, one of which is questions or instructions, the other is responses to these instructions.","metadata":{}},{"cell_type":"markdown","source":"### Inputs and Outputs\n* Input: Gemma models take in text strings, which can range from questions and prompts to longer documents that require summarization.\n* Output: In response, they generate text in English, offering answers, summaries, or other forms of text-based output, tailored to the input provided.\n\n<div style=\"text-align:center;\">\n    <img src=\"https://www.kaggle.com/competitions/64148/images/header\" alt=\"Gemma Model\" style=\"width:50%;\"/>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"## 2. Package Installation and Importing Libraries\n\n* `huggingface_hub`: This library provides access to models, datasets, and other resources shared by the Hugging Face community.\n\n* `transformers`: Formerly known as `pytorch-transformers` or `pytorch-pretrained-bert`, this library is developed by Hugging Face. It provides state-of-the-art pre-trained models for natural language understanding (NLU) and natural language generation (NLG) tasks.\n\n* `accelerate`: Accelerate is a library developed by Hugging Face that simplifies distributed training for deep learning models and provides an easy-to-use interface for distributed computing frameworks.\n\n* `BitsAndBytes`: This library provides functions and utilities for working with binary data in Python. It includes functions for performing bitwise operations.\n\n* `trl`: The Text Representation Learning (TRL) library is developed by Hugging Face and provides tools and utilities for training and fine-tuning text representations.\n\n* `peft`: PEFT (PyTorch Extensible Fine-Tuning) is a library that extends PyTorch for fine-tuning large language models (LLMs) such as GPT and BERT.","metadata":{}},{"cell_type":"code","source":"!pip install -q -U huggingface_hub\n!pip install -q -U transformers\n!pip install -q -U accelerate\n!pip install -q -U BitsAndBytes\n%pip install -q trl\n%pip install -q peft","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-04-15T12:02:18.694250Z","iopub.execute_input":"2024-04-15T12:02:18.694555Z","iopub.status.idle":"2024-04-15T12:03:38.079708Z","shell.execute_reply.started":"2024-04-15T12:02:18.694527Z","shell.execute_reply":"2024-04-15T12:03:38.078472Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Python basic module**\n* `os`: Provides ways to interact with the operating system and its environment variables.\n* `torch`: PyTorch library for deep learning applications.\n* `pandas`: Powerful data processing tool, ideal for handling CSV files and other forms of structured data.\n* `re` : Provides support for working with regular expressions, enabling powerful pattern-based string operations.\n\n**Transformers module**\n* `AutoTokenizer`: Used to automatically load a pre-trained tokenizer.\n* `AutoModelForCausalLM`: Used to automatically load pre-trained models for causal language modeling.\n* `BitsAndBytesConfig`: Configuration class for setting up the Bits and Bytes tokenizer.\n* `AutoConfig`: Used to automatically load the model's configuration.\n* `TrainingArguments`: Defines arguments for training setup.\n\n**Wordcloud module**\n* `WordCloud` : Python library used for generating word clouds, which are visual representations of text data where the size of each word indicates its frequency or importance.\n* `STOPWORDS` : set of commonly used words that are often excluded from text analysis because they typically do not carry significant meaning or contribute to the understanding of the text. \n\n**Datasets module**\n* `Dataset`: A class for handling datasets.\n\n**Peft module**\n* `LoraConfig` : A configuration class for configuring the Lora model.\n* `PeftModel`: A class that defines the PEFT model.\n* `prepare_model_for_kbit_training` : A function that prepares a model for k-bit training.\n* `get_peft_model` : Function to get the PEFT model.\n\n**trl module**\n* `SFTTrainer`: Trainer class for SFT (Supervised Fine-Tuning) training.\n\n**IPython.display module**\n* `Markdown` : Used to output text in Markdown format.\n* `display` : Used to display objects in Jupyter notebooks.","metadata":{}},{"cell_type":"code","source":"import torch\nimport os\nimport pandas as pd\nimport re\nimport matplotlib.pyplot as plt\nfrom transformers import AutoTokenizer, AutoModelForCausalLM,BitsAndBytesConfig, AutoConfig, TrainingArguments, pipeline\nfrom wordcloud import WordCloud, STOPWORDS\nfrom datasets import Dataset\nfrom peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\nfrom trl import SFTTrainer\nfrom IPython.display import Markdown as md\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-04-15T12:03:38.081469Z","iopub.execute_input":"2024-04-15T12:03:38.081800Z","iopub.status.idle":"2024-04-15T12:03:57.006388Z","shell.execute_reply.started":"2024-04-15T12:03:38.081771Z","shell.execute_reply":"2024-04-15T12:03:57.005474Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-04-15 12:03:47.294425: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-15 12:03:47.294532: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-15 12:03:47.434033: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\n\naccess_token=UserSecretsClient().get_secret('HUGGING_FACE')\nlogin(token=access_token)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-04-15T12:03:57.007555Z","iopub.execute_input":"2024-04-15T12:03:57.008279Z","iopub.status.idle":"2024-04-15T12:03:57.899300Z","shell.execute_reply.started":"2024-04-15T12:03:57.008242Z","shell.execute_reply":"2024-04-15T12:03:57.896205Z"},"trusted":true},"execution_count":3,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBackendError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m login\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkaggle_secrets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UserSecretsClient\n\u001b[0;32m----> 4\u001b[0m access_token\u001b[38;5;241m=\u001b[39m\u001b[43mUserSecretsClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_secret\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHUGGING_FACE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m login(token\u001b[38;5;241m=\u001b[39maccess_token)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/kaggle_secrets.py:64\u001b[0m, in \u001b[0;36mUserSecretsClient.get_secret\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ValidationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel must be non-empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m request_body \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m: label,\n\u001b[1;32m     63\u001b[0m }\n\u001b[0;32m---> 64\u001b[0m response_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweb_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_post_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET_USER_SECRET_BY_LABEL_ENDPOINT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msecret\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m response_json:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BackendError(\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnexpected response from the service. Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_json\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/kaggle_web_client.py:49\u001b[0m, in \u001b[0;36mKaggleWebClient.make_post_request\u001b[0;34m(self, data, endpoint, timeout)\u001b[0m\n\u001b[1;32m     47\u001b[0m         response_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response_json\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwasSuccessful\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m response_json:\n\u001b[0;32m---> 49\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m BackendError(\n\u001b[1;32m     50\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnexpected response from the service. Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_json\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (URLError, socket\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;28;01mas\u001b[39;00m e:\n","\u001b[0;31mBackendError\u001b[0m: Unexpected response from the service. Response: {'errors': ['No user secrets exist for kernel id 54730026 and label HUGGING_FACE.'], 'error': {'code': 5, 'details': []}, 'wasSuccessful': False}."],"ename":"BackendError","evalue":"Unexpected response from the service. Response: {'errors': ['No user secrets exist for kernel id 54730026 and label HUGGING_FACE.'], 'error': {'code': 5, 'details': []}, 'wasSuccessful': False}.","output_type":"error"}]},{"cell_type":"markdown","source":"#### Check if CUDA is available","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-15T12:03:57.900307Z","iopub.status.idle":"2024-04-15T12:03:57.900694Z","shell.execute_reply.started":"2024-04-15T12:03:57.900505Z","shell.execute_reply":"2024-04-15T12:03:57.900522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntokenizer= AutoTokenizer.from_pretrained(\"/kaggle/input/gemma/transformers/2b-it/3\")\nquantization_config=BitsAndBytesConfig(\n                    load_in_4bit=True,\n                    bnb_4bit_use_double_quant=True,\n                    bnb_4bit_quant_type='nf4',\n                    bnb_4bit_compute_dtype=torch.bfloat16,)\nmodel = AutoModelForCausalLM.from_pretrained(\"/kaggle/input/gemma/transformers/2b-it/3\",quantization_config=quantization_config,low_cpu_mem_usage=True)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T12:03:57.902433Z","iopub.status.idle":"2024-04-15T12:03:57.902821Z","shell.execute_reply.started":"2024-04-15T12:03:57.902619Z","shell.execute_reply":"2024-04-15T12:03:57.902635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ninput_text='What are the basic concepts of Data Science?'\ninput_ids=tokenizer(input_text,return_tensors='pt').to(\"cuda\")\noutputs=model.generate(**input_ids,max_new_tokens=256)\n\nprint(tokenizer.decode(outputs[0]))","metadata":{"execution":{"iopub.status.busy":"2024-04-15T12:03:57.904160Z","iopub.status.idle":"2024-04-15T12:03:57.904476Z","shell.execute_reply.started":"2024-04-15T12:03:57.904315Z","shell.execute_reply":"2024-04-15T12:03:57.904328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/1000-data-science-concepts/data_science_concepts.csv')\ndataset= Dataset.from_pandas(data)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T12:03:57.905329Z","iopub.status.idle":"2024-04-15T12:03:57.905628Z","shell.execute_reply.started":"2024-04-15T12:03:57.905478Z","shell.execute_reply":"2024-04-15T12:03:57.905491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Dataset Information and Null Value Check\n* Check the number of features and values in dataset.\n* Check for any NULL values in the dataset","metadata":{}},{"cell_type":"code","source":"print(\"Information of Dataset: \")\nprint(data.info(),'\\n')\n\nprint(\"Check for NULL values: \")\nprint(data.isnull().sum().sum())","metadata":{"execution":{"iopub.status.busy":"2024-04-15T12:03:57.907170Z","iopub.status.idle":"2024-04-15T12:03:57.907521Z","shell.execute_reply.started":"2024-04-15T12:03:57.907339Z","shell.execute_reply":"2024-04-15T12:03:57.907353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comment_words = ''\nstopwords = set(STOPWORDS)\n\n# Create subplots\nfig, axs = plt.subplots(1, len(data.columns), figsize=(10, 6))\n\n# Define the colormap\ncolormap = 'viridis'\n\n# Iterate through the csv file\nfor i, col in enumerate(data.columns):\n    # Concatenate all values in the column into a single string\n    # and convert to lowercase\n    comment_words += ' '.join(str(val).upper() for val in data[col]) + ' '\n\n    # Generate WordCloud for the current column\n    wordcloud = WordCloud(width=500, height=500,\n                          stopwords=stopwords,\n                          min_font_size=8,\n                          colormap=colormap).generate(comment_words)\n\n    # Plot the WordCloud image\n    axs[i].imshow(wordcloud, interpolation='bilinear')\n    axs[i].axis(\"off\")\n    axs[i].set_title(f\"Word Cloud for {col}\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T12:03:57.908934Z","iopub.status.idle":"2024-04-15T12:03:57.909236Z","shell.execute_reply.started":"2024-04-15T12:03:57.909087Z","shell.execute_reply":"2024-04-15T12:03:57.909100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 7. Defining Functions\nThis Python code defines two functions:\n\n1. **generate_DS_answers** : This function generates answers to a given prompt related to Data Science. It first constructs a prompt template using a provided context. Then, it creates a message containing the prompt using the tokenizer's apply_chat_template method. Next, it encodes the prompt into tokens, sends it to the GPU for processing, generates a response using the model, and decodes the output tokens into text. Finally, it returns the generated response.\n\n2. **extract_content** : This function extracts the content from a given text that comes after the marker <start_of_turn>model. It searches for this marker in the text and returns the content that follows it. If the marker is not found, it returns a message indicating that the content was not found.\n\nThese functions work together to generate responses to prompts related to Data Science and extract the relevant content from generated text.","metadata":{}},{"cell_type":"code","source":"max_new_tokens=300\ndef generate_DS_answers(context):\n    prompt_template=f\"\"\"Provide the Answer for the following Question in 300 words.\n    Provide only useful information:\n    Context:{context}\n    \n    Output: \"\"\"\n    \n    messages=[\n        {\"role\": \"user\",\"content\": prompt_template},\n        ]\n    prompt= tokenizer.apply_chat_template(messages,tokenize=False,add_generation_prompt=True)\n    input_ids=tokenizer.encode(prompt,add_special_tokens=True,return_tensors='pt').to(\"cuda\")\n    \n    # 100 tokens = 75 words\n    outputs=model.generate(input_ids,max_new_tokens=500)\n\n    response=tokenizer.decode(outputs[0])\n    \n    return response\n\ndef extract_content(text):\n    index=text.find('<start_of_turn>model')\n  \n    if index!=-1:\n        content_after_model=text[index+len('<start_of_turn>model'):].strip()\n    else:\n        return \"Content not found after '<start_of_turn>model'\"\n    return content_after_model\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T12:03:57.910602Z","iopub.status.idle":"2024-04-15T12:03:57.910955Z","shell.execute_reply.started":"2024-04-15T12:03:57.910796Z","shell.execute_reply":"2024-04-15T12:03:57.910811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context=\"Question: \"+dataset['Question'][0]\nprint(context)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T12:03:57.911877Z","iopub.status.idle":"2024-04-15T12:03:57.912203Z","shell.execute_reply.started":"2024-04-15T12:03:57.912045Z","shell.execute_reply":"2024-04-15T12:03:57.912059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Generate Response for a given input from Dataset","metadata":{}},{"cell_type":"code","source":"Answers=generate_DS_answers(context)\nprint(Answers)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T12:03:57.913496Z","iopub.status.idle":"2024-04-15T12:03:57.913841Z","shell.execute_reply.started":"2024-04-15T12:03:57.913676Z","shell.execute_reply":"2024-04-15T12:03:57.913693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Check for Relevant Information","metadata":{}},{"cell_type":"code","source":"Answers=extract_content(Answers)\nmd(Answers)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T12:03:57.915364Z","iopub.status.idle":"2024-04-15T12:03:57.915729Z","shell.execute_reply.started":"2024-04-15T12:03:57.915535Z","shell.execute_reply":"2024-04-15T12:03:57.915550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 8. Test Model before Fine Tuning\n\nBefore we start the finetuning process, let's see how the Gemma model performs out of the box on our dataset. This section will show you how to run a simple question-answering test.","metadata":{}},{"cell_type":"code","source":"for i in range(3):\n    context = \"### Question: \" + dataset['Question'][i]\n    display(md(context))\n    display(md(\"### Answer: \"))\n    display(md(extract_content(generate_DS_answers(context))))\n    print('\\n\\n')","metadata":{"execution":{"iopub.status.busy":"2024-04-15T12:03:57.917361Z","iopub.status.idle":"2024-04-15T12:03:57.917732Z","shell.execute_reply.started":"2024-04-15T12:03:57.917541Z","shell.execute_reply":"2024-04-15T12:03:57.917556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 9. Fine Tune Gemma\n\n* Define a formatting function for the model output.\n\n* WANDB is a useful tool for experiment tracking in machine learning. You might disable WANDB if you don't need experiment tracking or for debugging purposes.\n","metadata":{}},{"cell_type":"code","source":"def formatting_func(example):\n    template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n    line = template.format(instruction=example['Question'], response=example['Answer'])\n    return [line]\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2024-04-15T12:03:57.919064Z","iopub.status.idle":"2024-04-15T12:03:57.919364Z","shell.execute_reply.started":"2024-04-15T12:03:57.919215Z","shell.execute_reply":"2024-04-15T12:03:57.919227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r = 8,\n    target_modules = [\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n    task_type = \"CAUSAL_LM\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T12:03:57.920435Z","iopub.status.idle":"2024-04-15T12:03:57.920793Z","shell.execute_reply.started":"2024-04-15T12:03:57.920604Z","shell.execute_reply":"2024-04-15T12:03:57.920618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset,\n    max_seq_length=512,\n    args=TrainingArguments(\n        per_device_train_batch_size=1,\n        gradient_accumulation_steps=4,\n        warmup_steps=2,\n        max_steps=100,\n        learning_rate=2e-4,\n        fp16=True,\n        logging_steps=1,\n        output_dir=\"outputs\",\n        optim=\"paged_adamw_8bit\"\n    ),\n    peft_config=lora_config,\n    formatting_func=formatting_func,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T12:03:57.922000Z","iopub.status.idle":"2024-04-15T12:03:57.922320Z","shell.execute_reply.started":"2024-04-15T12:03:57.922161Z","shell.execute_reply":"2024-04-15T12:03:57.922175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-15T12:03:57.924174Z","iopub.status.idle":"2024-04-15T12:03:57.924619Z","shell.execute_reply.started":"2024-04-15T12:03:57.924386Z","shell.execute_reply":"2024-04-15T12:03:57.924404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context = \"### Question: \" + \"What are the Basic Concepts of Data Science?\"\ndisplay(md(context))\ndisplay(md(\"### Answer: \"))\ndisplay(md(extract_content(generate_DS_answers(context))))\nprint('\\n')","metadata":{"execution":{"iopub.status.busy":"2024-04-15T12:03:57.926202Z","iopub.status.idle":"2024-04-15T12:03:57.926674Z","shell.execute_reply.started":"2024-04-15T12:03:57.926411Z","shell.execute_reply":"2024-04-15T12:03:57.926430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(3):\n    context = \"### Question: \" + dataset['Question'][i]\n    display(md(context))\n    display(md(\"### Answer: \"))\n    display(md(extract_content(generate_DS_answers(context))))\n    print('\\n')","metadata":{"execution":{"iopub.status.busy":"2024-04-15T12:03:57.928041Z","iopub.status.idle":"2024-04-15T12:03:57.928341Z","shell.execute_reply.started":"2024-04-15T12:03:57.928191Z","shell.execute_reply":"2024-04-15T12:03:57.928204Z"},"trusted":true},"execution_count":null,"outputs":[]}]}